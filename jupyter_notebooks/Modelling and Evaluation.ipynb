{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Modelling and Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objective:\n",
        " * Answer business requirement 2:\n",
        "    * The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
        "## Inputs\n",
        "* inputs/mildew_dataset/cherry-leaves/train\n",
        "* inputs/mildew_dataset/cherry-leaves/test\n",
        "* inputs/mildew_dataset/cherry-leaves/validation\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "* Images distribution plot in train, validation, and test set\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels\n",
        "* Machine learning model creation and training\n",
        "* Save trained model\n",
        "* Learning curve plot for model performance\n",
        "* Model evaluation on pickle file\n",
        "* Prediction on the random image file"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set Data Directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "! pip install -r /workspaces/Project-5-Mildew-detection-leaves-images-identification/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import regular packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory\n",
        "\n",
        "* To change the working directory from its current folder to its parent folder\n",
        "* To access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "**To make the parent of the current directory the new current directory**\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chdir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "**To confirm the new current directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set input directories\n",
        "### Set train, validation, and test sets paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set paths for train, validation, and test sets\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "validation_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set output directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set output directories\n",
        "version = 'v1' \n",
        "file_path =f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'): \n",
        "    print('Existing version already available create a new version')\n",
        "    pass \n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set label names\n",
        "labels = os.listdir(train_path)\n",
        "print('Label for the images is', labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Identify Number of Images in train, validation, and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([]) \n",
        "for folder in ['train', 'validation', 'test']:\n",
        "  for label in labels:\n",
        "    df_freq = df_freq.append(\n",
        "        pd.Series(data={'Set': folder,\n",
        "                        'Label': label,\n",
        "                        'Frequency':int(len(os.listdir(my_data_dir+'/'+ folder + '/' + label)))}\n",
        "                  ),\n",
        "        ignore_index=True\n",
        "    )\n",
        "    \n",
        "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Image data augmentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset only shows a limited number of images, therefore there is a need to augment the images to increase the learning capacity of the machine learning model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ImageDataGenerator\n",
        "### Import ImageDataGenerator form Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(rotation_range=15,\n",
        "                                   width_shift_range=0.12, \n",
        "                                   height_shift_range=0.10,\n",
        "                                   shear_range=0.1,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest',\n",
        "                                   rescale=1./255\n",
        "                              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set the batch size\n",
        "batch_size = 20 \n",
        "# Augment training image dataset\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                              target_size=image_shape[:2],\n",
        "                                              color_mode='rgb',\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='binary',\n",
        "                                              shuffle=True\n",
        "                                              )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Augment validation image dataset\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                          target_size=image_shape[:2],\n",
        "                                                          color_mode='rgb',\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          class_mode='binary',\n",
        "                                                          shuffle=False\n",
        "                                                          )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Augment test image dataset\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    color_mode='rgb',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle=False\n",
        "                                                    )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Plot augmented training images\n",
        "for _ in range(3):\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)   #  (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Plot augmented validation images\n",
        "for _ in range(3):\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)   #  (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Plot augmented test images\n",
        "for _ in range(3):\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)   \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save class indices as a pickle file\n",
        "joblib.dump(value=train_set.class_indices ,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model creation\n",
        "## Create the machine learning Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow import keras\n",
        "import keras_tuner"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Declare a function to create model\n",
        "def build_tf_model():\n",
        "    \"\"\"\n",
        "    Convolution layers to filter the dominant pixel values from the non-dominant. \n",
        "    Maxpooling to reduce the image to only the dominant pixel values. \n",
        "    As a result the complexity is reduced and the accuracy increased.\n",
        "    The activation types used are relu (rectified linerar activation function) \n",
        "    and sigmoid (logistic regression classification function).\n",
        "    \"\"\" \n",
        "    # https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Convolution layers\n",
        "    model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
        "    # Maxpooling layers\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # The Flatten layer to transform the matrix into a vector (a single list of all values)\n",
        "    model.add(Flatten())\n",
        "    # The Vector produced from the Flatten is fed to the Dense layer\n",
        "    # The Dense layer to perform the mathematical calculation and provides the output \n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    \n",
        "    # Dropout layer \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    \n",
        "    model.compile(\n",
        "\n",
        "        loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy']\n",
        "                  )\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "build_tf_model().summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to create Keras tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Declare function to create Keras tuning model\n",
        "def build_tf_model(units, activation, dropout, lr):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=units, activation=activation))\n",
        "    if dropout:\n",
        "        model.add(Dropout(rate=0.25))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Function to build model\n",
        "def build_model(hp):\n",
        "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
        "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "    dropout = hp.Boolean(\"dropout\")\n",
        "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    # call existing model-building code with the hyperparameter values.\n",
        "    model = build_tf_model(\n",
        "        units=units, activation=activation, dropout=dropout, lr=lr\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialise the tuner\n",
        "### Set path for the search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tune_results = my_data_dir + '/tune'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialise the tuner\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=5,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"tune_results\",\n",
        "    project_name=\"mildew-detection\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the MNIST dataset to inform the tuning search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# To prepare the MNIST dataset to inform the tuning search\n",
        "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x[:-10000]\n",
        "x_validation = x[-10000:]\n",
        "y_train = y[:-10000]\n",
        "y_validation = y[-10000:]\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_validation = np.expand_dims(x_validation, -1).astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Search for the best hyperparameter configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_validation, y_validation))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query the search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# To get the top two models\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "# Build the model\n",
        "# This is needed for 'Sequential' without specified 'input_shape'\n",
        "best_model.build(input_shape=(None, 28, 28))\n",
        "best_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Re-instantiate the original model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tf_model():\n",
        "    \"\"\"\n",
        "    Convolution layers to filter the dominant pixel values from the non-dominant. \n",
        "    Maxpooling to reduce the image to only the dominant pixel values. \n",
        "    As a result the complexity is reduced and the accuracy increased.\n",
        "    The activation types used are relu (rectified linerar activation function) \n",
        "    and sigmoid (logistic regression classification function).\n",
        "    \"\"\" \n",
        "    # https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Convolution layers\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
        "    # Max pooling layers\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # The Flatten layer transforms the matrix into a vector (a simgle list f all values)\n",
        "    model.add(Flatten())\n",
        "    # The Vector produced from the Flatten is fed to the Dense layer\n",
        "    # The Dense layer to perform the mathematical calculation and provides the output \n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    \n",
        "    # Dropout layer \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    \n",
        "    model.compile(\n",
        "\n",
        "        loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy']\n",
        "                  )\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "model =  model = build_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch = len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/mildew_detection_model.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Performance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning curve of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss','val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy','val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "### Load the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('outputs/v1/mildew_detection_model.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the model evaluation as a pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation ,\n",
        "            filename=f\"outputs/v1/model_evaluation.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test prediction using a random image\n",
        "### Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 27\n",
        "label = labels[0] # select Healthy or Infected\n",
        "\n",
        "pil_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/'+ label)[pointer],\n",
        "                          target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert image to array and prepare for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "my_arr_image = image.img_to_array(pil_image)\n",
        "my_arr_image = np.expand_dims(my_arr_image, axis=0)/255\n",
        "print(my_arr_image.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "pred_prob = model.predict(my_arr_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_prob > 0.5]  \n",
        "\n",
        "if pred_class == target_map[0]: \n",
        "    pred_prob = 1 - pred_prob\n",
        "\n",
        "print(pred_prob)\n",
        "print(pred_class)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ML model performance matrics show that model was trained, validated, and tested using the available image dataset.\n",
        "* ML model performance matrics show an accuracy higher than the required 97% on both the train and test set.\n",
        "* The tuning results show that Keras tuning model was build well for hyperparameter optimization."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo\n",
        "## Push generated/new files from this Session to GitHub repository"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "source": [
        "### Git add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Git commit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!git commit -am \"save model\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!git push"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
